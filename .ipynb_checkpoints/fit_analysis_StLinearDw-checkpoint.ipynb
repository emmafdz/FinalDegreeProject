{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "plt.figure()\n",
    "for mu in [0.1,0.3,0.5,0.7]:\n",
    "\n",
    "    variance = 0.1\n",
    "    sigma = math.sqrt(variance)\n",
    "    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "    plt.plot(x, stats.norm.pdf(x, mu, sigma))\n",
    "plt.xlabel(\"${\\Theta}$\", fontsize = 24)\n",
    "plt.ylabel(\"firing rate (sp/sec)\", fontsize = 24)\n",
    "plt.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis of a 2AFC task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifiable variables when changing computer location:\n",
    "# Directory where the images will be stored:\n",
    "directory_images = '/home/emma/github/TFG/results/fit_model/'\n",
    "directory_functions = '/home/emma/github/TFG/functions'\n",
    "directory_data = '/home/emma/github/TFG/data/'\n",
    "directory_results = '/home/emma/github/TFG/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the libraries that will be used\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import json \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Insert path where the functions are stored\n",
    "sys.path.insert(1, directory_functions)\n",
    "\n",
    "# Importing the functions that will be used\n",
    "import rat_functions1 as rf\n",
    "import help_plot as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the data into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the rats\n",
    "rats = [\"Rat 24 05 sec\",\"Rat 25 05 sec\",\"Rat 36 05 sec\", \"Rat 37 05 sec\",\"Rat 25 1 sec\",\" Rat 35 1 sec\",\"Rat 37 1 sec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open processed data and store data into variables\n",
    "# with open(directory_data+\"processed_data.json\",\"r\") as f:\n",
    "#     data = json.load(f)\n",
    "#     stimulus = data[0]             # Data frames obtained from a gaussian distribution of a determined coherence\n",
    "#     coherences = data[1]         # Target coherences used for each trial\n",
    "#     rewards = data[2]              # Correct choice side\n",
    "#     decisions = data[3]            # Actual decision made by the rat each trial\n",
    "#     performances = data[4]     # 0 if the rat chose the correct choice, 1 if the rat chose the incorrect choice\n",
    "#     target_sigmas = data[5]     # Target sigma to use for each trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the fit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_total = []\n",
    "param_fits = []\n",
    "hessian = []\n",
    "for rat in [\"24\",\"25\",\"36\",\"37\"]:\n",
    "#for rat in [\"rat24\"]:\n",
    "    # Opening JSON file \n",
    "    f = open(directory_results+'model_fitStLinTimeDw/rat'+rat+'_05sec.json',) \n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    f.close()\n",
    "    print(len(data[\"ci\"]))\n",
    "    data.pop(\"ci\")\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    index_min=[]\n",
    "    imin1=data[\"LL_training\"].idxmin()\n",
    "    #print(df.loc[imin1][\"LL_training\"])\n",
    "    \n",
    "    LL=data.loc[imin1][\"LL_training\"]\n",
    "    hessian.append(data.loc[imin1][\"hessian\"])\n",
    "    param_fits.append(data.loc[imin1][\"param_all\"])\n",
    "    print(rat)\n",
    "    if rat==\"rat24\":\n",
    "        data.loc[imin1][\"LL_training\"]\n",
    "        #Nparam[model].append(len(df.loc[imin1][\"param_fit\"]))\n",
    "        Nparam = len(data.loc[imin1][\"param_fit\"])\n",
    "    print(data.loc[imin1][\"param_all\"])\n",
    "    PR_total.append(data.loc[imin1][\"PR_training\"])\n",
    "    \n",
    "for rat in [\"rat25\",\"rat35\",\"rat37\"]:\n",
    "\n",
    "    # Opening JSON file \n",
    "    f = open(directory_results+'model_fitStLinTimeDw/'+rat+'_1sec.json',) \n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    data.pop(\"ci\")\n",
    "\n",
    "    f.close()\n",
    "    data = pd.DataFrame(data)\n",
    "    index_min=[]\n",
    "    imin1=data[\"LL_training\"].idxmin()\n",
    "    #print(df.loc[imin1][\"LL_training\"])\n",
    "    print(rat)\n",
    "    LL=data.loc[imin1][\"LL_training\"]\n",
    "    param_fits.append(data.loc[imin1][\"param_all\"])\n",
    "    hessian.append(data.loc[imin1][\"hessian\"])\n",
    "   \n",
    "    if rat==\"rat25\":\n",
    "        data.loc[imin1][\"LL_training\"]\n",
    "        #Nparam[model].append(len(df.loc[imin1][\"param_fit\"]))\n",
    "        Nparam = len(data.loc[imin1][\"param_fit\"])\n",
    "    print(data.loc[imin1][\"param_all\"])\n",
    "    PR_total.append(data.loc[imin1][\"PR_training\"])\n",
    "# param_fits = np.delete(param_fits,2,0)\n",
    "# PR_total = np.delete(PR_total,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rat in range(len(rats)):\n",
    "    fig,axs = plt.subplots()\n",
    "    pote = [-(1.5)*x-(param_fits[rat][\"c2\"][0]/2.)*x**2+(1/4.)*param_fits[rat][\"c4\"][0]*x**4 for x in np.arange(-20,20,1)/10]\n",
    "    axs.plot(pote,linewidth = 4)\n",
    "    fig.suptitle(\"Decision module: DW\",fontsize = 20)\n",
    "    axs.yaxis.set_visible(False)\n",
    "    axs.xaxis.set_visible(False)\n",
    "    axs.spines[\"top\"].set_visible(False)\n",
    "    axs.spines[\"bottom\"].set_visible(False)\n",
    "    axs.spines[\"left\"].set_visible(False)\n",
    "    axs.spines[\"right\"].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rat in range(len(rats)):\n",
    "    c2 = 6\n",
    "    c4= 0.04\n",
    "    pote = [-(1.5)*x-(c2/2)*x**2+(1/4.)*c4*x**4  for x in np.arange(-200,200,1)/10]\n",
    "    plt.figure()\n",
    "    plt.plot(pote,linewidth = 5,color = \"red\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rat in range(len(rats)):\n",
    "    dec = []\n",
    "    x = np.arange(-180000,180000,1)\n",
    "    dec = -0-2*x+0.04*x**3\n",
    "    plt.figure\n",
    "    plt.plot(x,dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(directory_results+'synthetic_data.json',) \n",
    "# returns JSON object as  \n",
    "# a dictionary \n",
    "data = json.load(f) \n",
    "PR2 = data[\"choices_10\"]\n",
    "f.close()\n",
    "print(len(PR_total[0]))\n",
    "plt.plot(PR2[100:200],PR_total[0][100:200],'.')\n",
    "plt.ylabel(\"PR brunton amb parametres del fit\")\n",
    "plt.xlabel(\"PR brunton amb els parametres originals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian[0]\n",
    "\n",
    "# #LOGISTIC DW\n",
    "# 'c2': [5.421400641465883, 0.0], 'st': [1.1271535878056669, 0.4316926736821919, 0.0, 0.0], 'sigma_a': [1.0], 'x0': [0.0, 0.0], 'bias_d': [0.0], 'c4': [1.8465328579790288], 'hbias_d': [0.0]}\n",
    "# # Dict{Any,Any} with 7 entries:\n",
    "#   \"c2\"      => [1.5, 0.0]\n",
    "#   \"st\"      => [0.15, 3.33333, 0.0, 0.0]\n",
    "#   \"sigma_a\" => [1.0]\n",
    "#   \"x0\"      => [0.0, 0.0]\n",
    "#   \"bias_d\"  => [0.0]\n",
    "#   \"c4\"      => [1.0]\n",
    "#   \"hbias_d\" => [0.0]\n",
    "\n",
    "\n",
    "# #LINEAR DW\n",
    "# {'c2': [0.92508197878409, 0.0], 'st': [5.264079307888127, 0.0, 0.0, 0.0], 'sigma_a': [1.0], 'x0': [0.0, 0.0], 'bias_d': [0.0], 'c4': [0.03236049775204927], 'hbias_d': [0.0]}\n",
    "# Index(['param_all', 'LL_training', 'ci', 'hessian', 'param_fit',\n",
    "#        'PR_training']\n",
    "# #   \"c2\"      => [1.0, 0.0]\n",
    "# #   \"st\"      => [5.0, 0.0]\n",
    "# #   \"sigma_a\" => [1.0]\n",
    "# #   \"x0\"      => [0.0, 0.0]\n",
    "# #   \"bias_d\"  => [0.0]\n",
    "# #   \"c4\"      => [0.04]\n",
    "# #   \"hbias_d\" => [0.0]\n",
    "\n",
    "# #LOGISTIC TIME DW\n",
    "# {'c2': [9.647596385893047, 0.0], 'st': [0.007027780736236732, 9.628053236466746, 4.494597278220852, 0.0], 'sigma_a': [1.0], 'x0': [0.0, 0.0], 'bias_d': [0.0], 'c4': [9.999491937671104], 'hbias_d': [0.0]}\n",
    "# # Dict{Any,Any} with 7 entries:\n",
    "# # Dict{Any,Any} with 7 entries:\n",
    "# #   \"c2\"      => [1.5, 0.0]\n",
    "# #   \"st\"      => [0.15, 3.33333, 0.2, 0.0]\n",
    "# #   \"sigma_a\" => [1.0]\n",
    "# #   \"x0\"      => [0.0, 0.0]\n",
    "# #   \"bias_d\"  => [0.0]\n",
    "# #   \"c4\"      => [1.0]\n",
    "# #   \"hbias_d\" => [0.0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ci_rats = []\n",
    "for rat in range(len(rats)):\n",
    "    try:\n",
    "        inv_hess = np.linalg.inv((hessian[rat]))\n",
    "        ci = 2*(np.sqrt(np.diag(inv_hess)))\n",
    "        ci_rats.append(ci)\n",
    "        print(ci)\n",
    "    except:\n",
    "        ci_rats.append(np.zeros(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [axs1,axs2,axs3,axs4]= plt.subplots(1,4,figsize=(15,4))\n",
    "col = [\"blue\",\"purple\",\"lightblue\",\"pink\",\"orange\",\"cornflowerblue\",\"red\"]\n",
    "# for rat in range(len(rats)):\n",
    "# #     plt.plot(np.zeros(len(c2[rat]))+rat/100,c2[rat] ,\"o\",color = \"lightgrey\")\n",
    "#     plt.errorbar(rat/20,c2_min[rat],yerr=ci_rats[rat][0],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "#     plt.errorbar( rat/20+1,st1_min[rat],yerr=ci_rats[rat][1],marker =\"o\",color = col[rat])\n",
    "#     plt.xticks([0,1],[\"c2\",\"st1\"])\n",
    "#     plt.xlim([-0.1,5])\n",
    "#     plt.title(\"parameters\")\n",
    "#     plt.legend()\n",
    "# rats = [24]\n",
    "for rat in range(len(rats)):\n",
    "    axs1.errorbar(rat/10,param_fits[rat][\"c2\"][0],yerr=ci_rats[rat][0],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "    axs1.set_xticks([-0.2])\n",
    "    axs1.set_xlim([-0.1,1])\n",
    "    axs1.set_title(\"c2\")\n",
    "\n",
    "# for rat in range(len(rats)):\n",
    "#     axs2.errorbar(rat/10,param_fits[rat][\"c4\"][0],yerr=ci_rats[rat][3],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "#     axs2.set_xticks([-0.2])\n",
    "#     axs2.set_xlim([-0.1,1])\n",
    "#     axs2.set_title(\"c4\")\n",
    "    \n",
    "for rat in range(len(rats)):\n",
    "    axs3.errorbar(rat/10,param_fits[rat][\"st\"][0],yerr=ci_rats[rat][1],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "    axs3.set_xticks([-0.2])\n",
    "    axs3.set_xlim([-0.1,1])\n",
    "    axs3.set_title(\"st1\")\n",
    "for rat in range(len(rats)):\n",
    "    axs4.errorbar(rat/10,param_fits[rat][\"st\"][1],yerr=ci_rats[rat][2],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "    axs4.set_xticks([-0.2])\n",
    "    axs4.set_xlim([-0.1,1])\n",
    "    axs4.set_title(\"st2\")\n",
    "# for rat in range(len(rats)):\n",
    "#     axs2.plot( np.zeros(len(st1[rat]))+rat/10,st1[rat],\"o\",color = \"lightgrey\")\n",
    "#     axs2.errorbar( rat/10,st1_min[rat],yerr=ci_rats[rat][2],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "#     axs2.set_title(\"st1\")\n",
    "#     axs2.set_xticks([-0.2])\n",
    "#     axs2.set_xlim([-0.1,1])\n",
    "#     axs2.set_ylim([-10,110])\n",
    "\n",
    "# for rat in range(len(rats)):\n",
    "#     axs3.plot( np.zeros(len(st2[rat]))+rat/10,st2[rat],\"o\",color = \"lightgrey\")\n",
    "#     axs3.errorbar( rat/10,st2_min[rat],yerr=ci_rats[rat][3],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "#     axs3.set_title(\"st2\")\n",
    "#     axs3.set_xticks([-0.2])\n",
    "#     axs3.set_xlim([-0.1,1])\n",
    "\n",
    "# for rat in range(len(rats)):\n",
    "#     axs4.plot( np.zeros(len(st3[rat]))+rat/10,st3[rat],\"o\",color = \"lightgrey\")\n",
    "#     axs4.errorbar( rat/10,st3_min[rat],yerr=ci_rats[rat][4],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "#     axs4.set_title(\"st3\")\n",
    "#     axs4.set_xticks([-0.2])\n",
    "#     axs4.set_xlim([-0.1,1])\n",
    "#     axs4.set_ylim([-2.50,60])\n",
    "\n",
    "# for rat in range(len(rats)):\n",
    "#     axs5.plot( np.zeros(len(st4[rat]))+rat/10,st4[rat],\"o\",color = \"lightgrey\")\n",
    "#     axs5.errorbar( rat/10,st4_min[rat],yerr=ci_rats[rat][5],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "#     axs5.set_title(\"st4\")\n",
    "#     axs5.set_xticks([-0.2])\n",
    "#     axs5.set_xlim([-0.1,1])\n",
    "# #     plt.ylim([-2.50,30])\n",
    "    \n",
    "# for rat in range(len(rats)):\n",
    "#     axs6.plot( np.zeros(len(sigma_fit[rat]))+rat/10,sigma_fit[rat],\"o\",color = \"lightgrey\")\n",
    "#     axs6.errorbar( rat/10,sigma_fit_min[rat],yerr=ci_rats[rat][5],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "#     axs6.set_title(\"sigma\")\n",
    "#     axs6.set_xticks([-0.2])\n",
    "#     axs6.set_xlim([-0.1,1])\n",
    "# #     plt.ylim([-0.10,10])\n",
    "    \n",
    "\n",
    "# for rat in range(len(rats)):\n",
    "#     axs7.plot( np.zeros(len(x0_fit[rat]))+rat/10,x0_fit[rat],\"o\",color = \"lightgrey\")\n",
    "#     axs7.errorbar( rat/10,x0_min[rat],yerr=ci_rats[rat][3],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "#     axs7.set_title(\"x0\")\n",
    "#     axs7.set_xticks([-0.2])\n",
    "#     axs7.set_xlim([-0.1,1])\n",
    "#     axs7.set_ylim([-40,2.5])\n",
    "    \n",
    "\n",
    "# # for rat in range(len(rats)):\n",
    "# #     axs8.plot( np.zeros(len(biasd_fit[rat]))+rat/10,biasd_fit[rat],\"o\",color = \"lightgrey\")\n",
    "# #     axs8.errorbar( rat/10,biasd_min[rat],yerr=ci_rats[rat][4],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "# #     axs8.set_title(\"bias_d\")\n",
    "# #     axs8.set_xticks([-0.2])\n",
    "# #     axs8.set_xlim([-0.1,1])\n",
    "# #     axs8.set_ylim([-30,20])\n",
    "\n",
    "# # for rat in range(len(rats)):\n",
    "# #     axs9.plot( np.zeros(len(c2u_min[rat]))+rat/10,c2u_min[rat],\"o\",color = \"lightgrey\")\n",
    "# #     axs9.errorbar( rat/10,c2u_min[rat],yerr=ci_rats[rat][1],marker =\"o\",label = rats[rat],color = col[rat])\n",
    "# #     axs9.set_title(\"c2_u\")\n",
    "# #     axs9.set_xticks([-0.2])\n",
    "# #     axs9.set_xlim([-0.1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open fit stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus =[]\n",
    "coherences = []\n",
    "target_sigmas =[]\n",
    "rewards = []\n",
    "performances = []\n",
    "choices = []\n",
    "dates = []\n",
    "n_total_stimulus = []\n",
    "for rat in [24,25,36,37]:\n",
    "    print(rat)\n",
    "    # Opening JSON file \n",
    "    f = open(directory_data+'processed_data_rat'+str(rat)+'_dataset2_05.json',) \n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    f.close()\n",
    "    stimulus.append(data[\"stim_10\"])\n",
    "    coherences.append(data[\"coherences_10\"])\n",
    "    rewards.append(data[\"rewards_10\"])\n",
    "    target_sigmas.append(data[\"sigma_10\"])\n",
    "    choices.append(data[\"choices_10\"])\n",
    "    dates.append(data[\"date_10\"])\n",
    "    n_total_stimulus.append(data[\"n_stim_10\"])\n",
    "    performances.append(data[\"performance_10\"])\n",
    "    \n",
    "for rat in [25,35,37]:\n",
    "    print(rat)\n",
    "    # Opening JSON file \n",
    "    f = open(directory_data+'processed_data_rat'+str(rat)+'_dataset2_1.json',) \n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    f.close()\n",
    "    stimulus.append(data[\"stim_20\"])\n",
    "    coherences.append(data[\"coherences_20\"])\n",
    "    rewards.append(data[\"rewards_20\"])\n",
    "    target_sigmas.append(data[\"sigma_20\"])\n",
    "    choices.append(data[\"choices_20\"])\n",
    "    dates.append(data[\"date_20\"])\n",
    "    n_total_stimulus.append(data[\"n_stim_20\"])\n",
    "    performances.append(data[\"performance_20\"])\n",
    "\n",
    "# [\"Rat 24 0.5 sec\",\"Rat 25 0.5 sec\",\"Rat 25 1 sec\",\"Rat 35 1 sec\", \"Rat 36 0.5 sec\", \"Rat 37 0.5 sec\",\"Rat 37 1 sec\"]\n",
    "\n",
    "# stimulus[0],coherences[0],target_sigmas[0],rewards[0],performances[0],choices[0],dates[0] = data[0][0],  data[1][0],  data[5][0], data[2][0], data[4][0], data[3][0], data[6][0]\n",
    "# stimulus[1],coherences[1],target_sigmas[1],rewards[1],performances[1],choices[1],dates[1] = data[0][1],  data[1][1],  data[5][1], data[2][1], data[4][1], data[3][1], data[6][1]\n",
    "# stimulus[3],coherences[3],target_sigmas[3],rewards[3],performances[3],choices[3],dates[3] = data[0][3],  data[1][3],  data[5][3], data[2][3], data[4][3], data[3][3], data[6][3]\n",
    "# stimulus[4],coherences[4],target_sigmas[4],rewards[4],performances[4],choices[4],dates[4] = data[0][4],  data[1][4],  data[5][4], data[2][4], data[4][4], data[3][4], data[6][4]\n",
    "\n",
    "# # Opening JSON file \n",
    "# f = open(directory_data+'ordered_processed_dataset2_1sec.json',) \n",
    "# # returns JSON object as  \n",
    "# # a dictionary \n",
    "# data = json.load(f) \n",
    "# f.close()\n",
    "\n",
    "# stimulus[1],coherences[1],target_sigmas[1],rewards[1],performances[1],choices[1],dates[1] = data[0][1],  data[1][1],  data[5][1], data[2][1], data[4][1], data[3][1], data[6][1]\n",
    "# stimulus[2],coherences[2],target_sigmas[2],rewards[2],performances[2],choices[2],dates[2] = data[0][2],  data[1][2],  data[5][2], data[2][2], data[4][2], data[3][2], data[6][2]\n",
    "# # stimulus[4],coherences[4],target_sigmas[4],rewards[4],performances[4],choices[4],dates[4] = data[0][4],  data[1][4],  data[5][4], data[2][4], data[4][4], data[3][4], data[6][4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stimulus)):\n",
    "    if i < 4:\n",
    "        stimulus[i] = (np.reshape(stimulus[i],(int(len(stimulus[i])/10),10)))\n",
    "        print(rats[i],len(choices[i]))\n",
    "    else:\n",
    "        stimulus[i] = (np.reshape(stimulus[i],(int(len(stimulus[i])/20),20)))\n",
    "        print(rats[i],len(choices[i]))        \n",
    "#     print(len(np.transpose(np.reshape(stimulus[i],(10,int(len(stimulus[i])/10))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR_total = []\n",
    "# for i in range(len(rats)):\n",
    "#     # Opening JSON file \n",
    "#     f = open(directory_results+'1model10C2St1St2Sig/PR_Rat'+str(i+1)+'.json',) \n",
    "#     # returns JSON object as  \n",
    "#     # a dictionary \n",
    "#     data = json.load(f) \n",
    "    \n",
    "#     f.close()\n",
    "#     PR_total.append(data[\"PR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(PR_total[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coherences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices_fit = []\n",
    "for rat in range(len(rats)):\n",
    "    choices1 = []\n",
    "    for prob in PR_total[rat]:\n",
    "        if np.random.rand() < prob:\n",
    "            choices1.append(1)\n",
    "        else:\n",
    "            choices1.append(0)\n",
    "    choices_fit.append(choices1)\n",
    "\n",
    "\n",
    "# choices_fit = []\n",
    "# for rat in range(len(rats)):\n",
    "#     choices1 = []\n",
    "#     choic= []\n",
    "#     for stim in stimulus[rat]:\n",
    "#         if (stim[0]+stim[1])+0.1*np.random.randn(1)>0:\n",
    "#             choices1.append(1)\n",
    "#         else:\n",
    "#             choices1.append(0)\n",
    "#     for stim in stimulus[rat]:\n",
    "#         if stim[0]+stim[1]>0:\n",
    "#             choic.append(1)\n",
    "#         else:\n",
    "#             choic.append(0)\n",
    "#     print(sum(choices1)/sum(choic))\n",
    "#     choices_fit.append(choices1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = []\n",
    "for rat in range(len(rats)):\n",
    "    months.append(len(rf.count(dates[rat]))/31)\n",
    "print(months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rat in range(len(rats)):\n",
    "#     acc = []\n",
    "#     div = 4*7\n",
    "#     tick = []\n",
    "#     counter = 0\n",
    "#     for i in range(int(months[rat]*div)):\n",
    "#         print(len(performances))\n",
    "#         s_performances = performances[rat][int((n_total_stimulus[rat]/(months[rat]*div))*i):int((n_total_stimulus[rat]/(months[rat]*div))*(i+1))]\n",
    "#         s_dates = dates[rat][int((n_total_stimulus[rat]/(months[rat]*div))*i):int((n_total_stimulus[rat]/(months[rat]*div))*(i+1))]\n",
    "#         acc.append(sum(s_performances)/len(s_performances))\n",
    "#         counter +=1\n",
    "#         if counter == 20:\n",
    "#             tick.append(s_dates[0][3:])\n",
    "#             counter = 0\n",
    "#     tick.append(s_dates[len(s_dates)-1][3:])\n",
    "#     plt.figure()\n",
    "#     plt.title(rats[rat]+\" accuracy\")\n",
    "#     plt.plot(np.arange(0,int(months[rat]*div),1),acc)\n",
    "#     plt.ylim([0,1])\n",
    "#     plt.xticks(np.arange(0,(len(tick))*20,np.round((len(acc)/(len(tick)-1)),2)),tick,rotation = \"vertical\")\n",
    "\n",
    "#     plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 1\n",
    "# t = 2\n",
    "# # end = len(stimulus)-1\n",
    "# stimulus = [stimulus[a][1000:len(stimulus[a])-1] for a in range(len(stimulus))]\n",
    "# # stimulus_test = stimulus[:][8000:10000]\n",
    "# coherences = [coherences[a][1000:len(stimulus[a])-1] for a in range(len(coherences))]\n",
    "# # coherences_test = coherences[:][8000:10000]\n",
    "# target_sigmas = [target_sigmas[a][1000:len(stimulus[a])-1] for a in range(len(target_sigmas))]\n",
    "# # target_sigmas_test = target_sigmas[:][8000:10000]\n",
    "# rewards =[rewards[a][1000:len(stimulus[a])-1] for a in range(len(rewards))]\n",
    "# # rewards_test = rewards[:][8000:10000]\n",
    "# performances =[performances[a][1000:len(stimulus[a])-1] for a in range(len(performances))]\n",
    "# # performances_test = performances[:][8000:10000]\n",
    "# choices = [choices[a][1000:len(stimulus[a])-1] for a in range(len(choices))]\n",
    "# # choices_test = choices[:][8000:10000]\n",
    "# choices_fit = [choices_fit[a][1000:len(stimulus[a])-1] for a in range(len(choices_fit))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "# t = 2\n",
    "# # end = len(stimulus)-1\n",
    "# stimulus = [stimulus[a][10000:len(stimulus[a])] for a in range(len(stimulus))]\n",
    "# # stimulus_test = stimulus[:][8000:10000]\n",
    "# coherences = [coherences[a][10000:len(stimulus[a])] for a in range(len(coherences))]\n",
    "# # coherences_test = coherences[:][8000:10000]\n",
    "# target_sigmas = [target_sigmas[a][10000:len(stimulus[a])] for a in range(len(target_sigmas))]\n",
    "# # target_sigmas_test = target_sigmas[:][8000:10000]\n",
    "# rewards =[rewards[a][10000:len(stimulus[a])] for a in range(len(rewards))]\n",
    "# # rewards_test = rewards[:][8000:10000]\n",
    "# performances =[performances[a][10000:len(stimulus[a])] for a in range(len(performances))]\n",
    "# # performances_test = performances[:][8000:10000]\n",
    "# choices = [choices[a][10000:len(stimulus[a])] for a in range(len(choices))]\n",
    "# # choices_test = choices[:][8000:10000]\n",
    "# choices_fit = [choices_fit[a][10000:len(stimulus[a])] for a in range(len(choices_fit))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st3 = [[0],[0],[0],[0],[0]]\n",
    "# st4 = [[0],[0],[0],[0],[0]]\n",
    "print(param_fits[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic DW TIME\n",
    "for rat in range(len(rats)):\n",
    "    ind = 0\n",
    "    leg = []\n",
    "    fig,axs1 = plt.subplots()\n",
    "    for param in param_fits[rat]:\n",
    "        for p in range(len(param_fits[rat][param])):\n",
    "            if param_fits[rat][param][p]!=0:\n",
    "                if param_fits[rat][param][p]!=1:\n",
    "                    leg.append(param+\" \"+str(p))\n",
    "                    axs1.errorbar(ind,param_fits[rat][param][p],yerr=ci_rats[rat][ind],marker =\"o\",label = param + str(p))\n",
    "                    axs1.scatter(ind, param_fits[rat][param][p], s =100, marker = \"o\")\n",
    "                    ind +=1\n",
    "    axs1.set_xticks([0,1,2,3])\n",
    "    axs1.set_xticklabels([\"$c_2$\",r\"$\\beta$\",r\"$\\beta_t$\",\"$c_4$\"],fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    fig.suptitle(\"Parameters fit\", fontsize = 20)\n",
    "    axs1.spines[\"top\"].set_visible(False)\n",
    "    axs1.spines[\"right\"].set_visible(False)\n",
    "    axs1.hlines(0,0,3,linestyle=\"dashed\",color=\"grey\")\n",
    "#     axs1.set_ylim([-1,5])\n",
    "#     axs1.set_xticks([-0.2])\n",
    "#     axs1.set_xlim([-0.1,1])\n",
    "#     axs1.set_title(\"c2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stimulus transformation \n",
    "transformed_stimulus = []\n",
    "for rat in range(len(rats)):\n",
    "    stimulus_transf = []\n",
    "    st1 = param_fits[rat][\"st\"][0]\n",
    "    st2 = param_fits[rat][\"st\"][1]\n",
    "#     st3 = param_fits[rat][\"st\"][2]\n",
    "    for stim in stimulus[rat]:\n",
    "        s_trans = []\n",
    "        for frame in range(len(stim)):\n",
    "            s_trans.append(stim[frame]*(st1*np.exp(st2*(frame-1))))\n",
    "           \n",
    "        stimulus_transf.append(s_trans)\n",
    "    transformed_stimulus.append(stimulus_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "colors = [\"k\",\"blue\",\"lightblue\"]\n",
    "for rat in range(len(rats)):\n",
    "    st1 = param_fits[rat][\"st\"][0]\n",
    "    st2 = param_fits[rat][\"st\"][1]\n",
    "    fig,axs = plt.subplots(figsize = (8,5))\n",
    "    c = 0\n",
    "    for t in [0,5,9]:\n",
    "        s_trans = []\n",
    "        for ph_stim in np.arange(-10,11,1):\n",
    "            frame = ph_stim/10\n",
    "            s_trans.append(frame*(st1*np.exp(st2*(t-1))))\n",
    "            \n",
    "\n",
    "        axs.plot(np.arange(-10,11,1)/10,s_trans,colors[c],linewidth = 4,label= \"t =  \"+str(t))\n",
    "        c += 1\n",
    "        hp.remove_axis(axs)\n",
    "            #     plt.ylim([-1,1])\n",
    "    fig.suptitle(\"Sensory module: linear with \\n time adpatation\",fontsize=24)\n",
    "    fig.text(0.5, 0.02, \"Physical stimulus\", ha='center',fontsize = 24)\n",
    "    fig.text(0.03, 0.5, \"Evidence\", va='center', rotation='vertical',fontsize = 24)\n",
    "    plt.xticks([-1,0,1],fontsize = 22)\n",
    "    plt.yticks([-6,0,6],fontsize=22)\n",
    "    axs.legend(fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separing the data by coherences (real and target)\n",
    "### Separing the data by target coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will compute a vector with the target coherences used for each rat\n",
    "coherence_vectors = [] # coherence_vectors[rat][coherence]\n",
    "\n",
    "for coh in coherences:\n",
    "    coh_vec = rf.return_coherences_vector(coh)\n",
    "    coherence_vectors.append(coh_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stimulus, coherences, rewards, decisions, performances and target sigmas will be divided by coherences\n",
    "results_divided_coherence = [] # The vector will be organized as follows: \n",
    "                                                  # results_divided_coherence[rat][coherence]=[rewards, decisions, performances, stimulus, target_sigmas]\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    divided_coherence = []\n",
    "    for coherence in coherence_vectors[rat]:\n",
    "        divided_coherence.append(rf.divide_coh(coherences[rat],rewards[rat],choices[rat],performances[rat],stimulus[rat],target_sigmas[rat],coherence))\n",
    "    results_divided_coherence.append(divided_coherence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(choices_fit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stimulus, coherences, rewards, decisions, performances and target sigmas will be divided by coherences\n",
    "results_divided_coherence_fit = [] # The vector will be organized as follows: \n",
    "                                                  # results_divided_coherence[rat][coherence]=[rewards, decisions, performances, stimulus, target_sigmas]\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    divided_coherence = []\n",
    "    for coherence in coherence_vectors[rat]:\n",
    "        divided_coherence.append(rf.divide_coh(coherences[rat],rewards[rat],choices_fit[rat],performances[rat],stimulus[rat],target_sigmas[rat],coherence))\n",
    "    results_divided_coherence_fit.append(divided_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_divided_coherence_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentages, the number of trials and the coherence vectors avobe x trials will be stored into the following variables for each rat:\n",
    "percentages = [] # percentages[rat][strong_coherence]\n",
    "total_number_trials = [] # total_number_trials[rat][strong_coherence]\n",
    "strong_coherence_vectors = [] # strong_coherence_vectors[rat] coherences which have more than 2500 trials\n",
    "\n",
    "n_trials_threshold = 100 # Only the coherences which have avobe n_trials_threshold will be used\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    perc = []\n",
    "    number_trials = []\n",
    "    coh_vector = []\n",
    "    # for each coherence which has more than n_trials_threshold, the percentage of right choice will be computed\n",
    "    for i in range(len(results_divided_coherence[rat])):\n",
    "        if len(results_divided_coherence[rat][i][1]) > n_trials_threshold:\n",
    "            perc.append(sum(results_divided_coherence[rat][i][1])/len(results_divided_coherence[rat][i][1]))\n",
    "            coh_vector.append(coherence_vectors[rat][i])\n",
    "            number_trials.append(len(results_divided_coherence[rat][i][1]))\n",
    "    percentages.append(perc)\n",
    "    total_number_trials.append(number_trials)\n",
    "    strong_coherence_vectors.append(coh_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentages, the number of trials and the coherence vectors avobe x trials will be stored into the following variables for each rat:\n",
    "percentages_fit = [] # percentages[rat][strong_coherence]\n",
    "total_number_trials_fit = [] # total_number_trials[rat][strong_coherence]\n",
    "strong_coherence_vectors_fit = [] # strong_coherence_vectors[rat] coherences which have more than 2500 trials\n",
    "\n",
    "n_trials_threshold = 100 # Only the coherences which have avobe n_trials_threshold will be used\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    perc = []\n",
    "    number_trials = []\n",
    "    coh_vector = []\n",
    "    # for each coherence which has more than n_trials_threshold, the percentage of right choice will be computed\n",
    "    for i in range(len(results_divided_coherence_fit[rat])):\n",
    "        if len(results_divided_coherence_fit[rat][i][1]) > n_trials_threshold:\n",
    "            perc.append(sum(results_divided_coherence_fit[rat][i][1])/len(results_divided_coherence_fit[rat][i][1]))\n",
    "            coh_vector.append(coherence_vectors[rat][i])\n",
    "            number_trials.append(len(results_divided_coherence[rat][i][1]))\n",
    "    percentages_fit.append(perc)\n",
    "    total_number_trials_fit.append(number_trials)\n",
    "    strong_coherence_vectors_fit.append(coh_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each rat, plot the psychometric curve with the coherence values which have above x trials\n",
    "# fig, axs = plt.subplots(figsize = (8,5))\n",
    "for rat in range(len(rats)):\n",
    "    fig, axs = plt.subplots(figsize = (8,5))\n",
    "    # Computing the confidence intervals (95%)\n",
    "    z = 1.96\n",
    "    conf_int = [[percentages[rat][i]-z*(np.sqrt((percentages[rat][i]*(1-percentages[rat][i]))/total_number_trials[rat][i])) for i in range(len(total_number_trials[rat]))],\n",
    "                [percentages[rat][i]+z*(np.sqrt((percentages[rat][i]*(1-percentages[rat][i]))/total_number_trials[rat][i])) for i in range(len(total_number_trials[rat]))]]\n",
    "    conf_int = [[percentages[rat][i]-conf_int[0][i] for i in range(len(percentages[rat]))],[conf_int[1][i]-percentages[rat][i] for i in range(len(percentages[rat]))]]\n",
    "    axs.errorbar(strong_coherence_vectors[rat],percentages[rat],conf_int,marker='o',label = \"Real data\", color =\"cornflowerblue\",linewidth=4,linestyle=\"dashed\")\n",
    "    conf_int = [[percentages_fit[rat][i]-z*(np.sqrt((percentages_fit[rat][i]*(1-percentages_fit[rat][i]))/total_number_trials_fit[rat][i])) for i in range(len(total_number_trials_fit[rat]))],\n",
    "                [percentages_fit[rat][i]+z*(np.sqrt((percentages_fit[rat][i]*(1-percentages_fit[rat][i]))/total_number_trials_fit[rat][i])) for i in range(len(total_number_trials_fit[rat]))]]\n",
    "    conf_int = [[percentages_fit[rat][i]-conf_int[0][i] for i in range(len(percentages_fit[rat]))],[conf_int[1][i]-percentages_fit[rat][i] for i in range(len(percentages_fit[rat]))]]\n",
    "#     axs.errorbar(strong_coherence_vectors_fit[rat],percentages_fit[rat],conf_int,marker='o',label = \"Fitted model\")\n",
    "    conf_int = [[percentages_fit[rat][i]-z*(np.sqrt((percentages_fit[rat][i]*(1-percentages_fit[rat][i]))/total_number_trials_fit[rat][i])) for i in range(len(total_number_trials_fit[rat]))],\n",
    "                [percentages_fit[rat][i]+z*(np.sqrt((percentages_fit[rat][i]*(1-percentages_fit[rat][i]))/total_number_trials_fit[rat][i])) for i in range(len(total_number_trials_fit[rat]))]]\n",
    "    axs.fill_between(strong_coherence_vectors_fit[rat],conf_int[0],conf_int[1],alpha=0.4,facecolor='grey', linewidth=4, linestyle='dashdot', antialiased=True,label = \"Fitted model\")\n",
    "\n",
    "#     fig.suptitle(\" Psychometric curve \"+rats[rat],fontsize = 22)\n",
    "    axs.legend(loc = \"upper left\",fontsize = 24)\n",
    "    fig.text(0.5, -0.02, \"Stimulus evidence (coherence)\", ha='center',fontsize = 28)\n",
    "    fig.text(-0.06, 0.5, \"Probability to \\n choose right\", va='center', rotation='vertical',fontsize = 28)\n",
    "    axs.axis([-1.1,1.1,0,1])\n",
    "    hp.xticks(axs,[-1,-0.5,0,0.5,1],xticklabels=None,fontsize=26)\n",
    "    hp.yticks(axs,[0,0.5,1],yticklabels = None,fontsize =26)\n",
    "\n",
    "    hp.remove_axis(axs)\n",
    "    plt.hlines(0.5,-1,1,linestyle='--',color='lightgrey')\n",
    "    plt.vlines(0,0.05,0.95,linestyle='--',color='lightgrey')\n",
    "\n",
    "# fig.savefig(directory_images+'psychometric_curves/psychometric_curves_target_coherences.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separing the data by sigma and coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will compute a vector with the sigma used for each rat and each coherence\n",
    "sigma_lists = [] #sigma_lists[rat][sigma]\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    sigma_list = []\n",
    "    for i in range(len(results_divided_coherence[rat])):\n",
    "        for a in rf.count(results_divided_coherence[rat][i][4]):\n",
    "            sigma_list.append(a)\n",
    "    sigma_list = rf.count(sigma_list)\n",
    "    sigma_list = sorted(sigma_list)\n",
    "    sigma_lists.append(sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will compute a vector with the sigma used for each rat and each coherence\n",
    "sigma_lists_fit = [] #sigma_lists[rat][sigma]\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    sigma_list = []\n",
    "    for i in range(len(results_divided_coherence_fit[rat])):\n",
    "        for a in rf.count(results_divided_coherence_fit[rat][i][4]):\n",
    "            sigma_list.append(a)\n",
    "    sigma_list = rf.count(sigma_list)\n",
    "    sigma_list = sorted(sigma_list)\n",
    "    sigma_lists_fit.append(sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for each sigma will be stored\n",
    "results_divided_sigma = [] # results_divided_sigma[rat][coherence][sigma][reward, decision, performance, stim]\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    divided_sigma = []\n",
    "    for i in range(len(results_divided_coherence[rat])):\n",
    "        results = []\n",
    "        for sigma in sigma_lists[rat]:\n",
    "            results.append(rf.divide_sigma(results_divided_coherence[rat][i][0],results_divided_coherence[rat][i][1],results_divided_coherence[rat][i][2],\n",
    "                                             results_divided_coherence[rat][i][3],results_divided_coherence[rat][i][4],sigma))\n",
    "        divided_sigma.append(results)\n",
    "    results_divided_sigma.append(divided_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for each sigma will be stored\n",
    "results_divided_sigma_fit = [] # results_divided_sigma[rat][coherence][sigma][reward, decision, performance, stim]\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    divided_sigma = []\n",
    "    for i in range(len(results_divided_coherence_fit[rat])):\n",
    "        results = []\n",
    "        for sigma in sigma_lists[rat]:\n",
    "            results.append(rf.divide_sigma(results_divided_coherence_fit[rat][i][0],results_divided_coherence_fit[rat][i][1],results_divided_coherence_fit[rat][i][2],\n",
    "                                             results_divided_coherence_fit[rat][i][3],results_divided_coherence_fit[rat][i][4],sigma))\n",
    "        divided_sigma.append(results)\n",
    "    results_divided_sigma_fit.append(divided_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_divided_sigma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percentages of right choice for the results_divided_sigma\n",
    "percentages_lists, coherences_lists, length_lists, length_all_rats = rf.compute_percentages(rats,results_divided_sigma,coherence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percentages of right choice for the results_divided_sigma\n",
    "percentages_lists_fit, coherences_lists_fit, length_lists_fit, length_all_rats_fit = rf.compute_percentages(rats,results_divided_sigma_fit,coherence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each rat, plot the psychometric curve with the coherence values which have above x trials\n",
    "# fig, axs = plt.subplots(figsize = (8,5))\n",
    "for rat in range(len(rats)):\n",
    "    for a in range(len(coherences_lists[rat])):\n",
    "            fig, axs = plt.subplots(figsize = (8,5))\n",
    "\n",
    "            # Computing the confidence intervals (95%)\n",
    "            z = 1.96\n",
    "            conf_int = [[percentages_lists[rat][a][i]-z*(np.sqrt((percentages_lists[rat][a][i]*(1-percentages_lists[rat][a][i]))/length_lists[rat][a][i])) for i in range(len(percentages_lists[rat][a]))],\n",
    "                        [percentages_lists[rat][a][i]+z*(np.sqrt((percentages_lists[rat][a][i]*(1-percentages_lists[rat][a][i]))/length_lists[rat][a][i])) for i in range(len(percentages_lists[rat][a]))]]\n",
    "            conf_int = [[percentages_lists[rat][a][i]-conf_int[0][i] for i in range(len(percentages_lists[rat][a]))],[conf_int[1][i]-percentages_lists[rat][a][i] for i in range(len(percentages_lists[rat][a]))]]\n",
    "            axs.errorbar(coherences_lists[rat][a],percentages_lists[rat][a],conf_int,marker='o',label = \"Real data\")\n",
    "            conf_int = [[percentages_lists_fit[rat][a][i]-z*(np.sqrt((percentages_lists_fit[rat][a][i]*(1-percentages_lists_fit[rat][a][i]))/length_lists_fit[rat][a][i])) for i in range(len(percentages_lists_fit[rat][a]))],\n",
    "                [percentages_lists_fit[rat][a][i]+z*(np.sqrt((percentages_lists_fit[rat][a][i]*(1-percentages_lists_fit[rat][a][i]))/length_lists_fit[rat][a][i])) for i in range(len(percentages_lists_fit[rat][a]))]]\n",
    "            axs.fill_between(coherences_lists_fit[rat][a],conf_int[0],conf_int[1],alpha=0.2,facecolor='#089FFF', linewidth=4, linestyle='dashdot', antialiased=True,label = \"Fitted model\")\n",
    "\n",
    "#             axs.plot(coherences_lists[rat][i],percentages_lists[rat][i],label=\"real psychometric curve\",marker = \"o\")\n",
    "            axs.axis([-1,1,0,1])\n",
    "            axs.vlines(0,-1,1,color = \"lightgrey\",linestyles = \"--\",label =\"x = 0\")\n",
    "            axs.hlines(0.5,-1,1,color = \"lightblue\",linestyles = \"--\",label = \"y = 0.5\")\n",
    "            fig.suptitle(rats[rat]+\" Psychometric curve for sigma \"+str(sigma_lists[rat][a]),fontsize = 18)\n",
    "            fig.text(0.5, 0.02, \"Stimulus evidence (coherence)\", ha='center',fontsize = 16)\n",
    "            fig.text(0.03, 0.5, \"Probability to choose right\", va='center', rotation='vertical',fontsize = 18)\n",
    "            axs.legend(loc = \"upper left\",fontsize = 12)\n",
    "            axs.spines['right'].set_visible(False)\n",
    "            axs.spines['top'].set_visible(False)\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "# fig.savefig(directory_images+'psychometric_curves/psychometric_curves_target_coherences.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing coherence distribution for each sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the coherence vector for all rats together\n",
    "coherences_all_rats = []\n",
    "for rat in range(len(rats)):\n",
    "    coherences_all_rats.append(coherence_vectors[rat])\n",
    "coherences_all_rats = rf.return_vector(coherences_all_rats)\n",
    "\n",
    "# Computing the sigma vector for all rats tohether\n",
    "\n",
    "sigmas_all_rats = rf.return_vector(sigma_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generates a file with a table of the number of trials for each coherence and sigma for all rats\n",
    "# rf.recount_trials_all_rats(sigma_lists,coherences_all_rats,length_all_rats,\"all rats\",coherence_vectors,rats,sigmas_all_rats,directory_images)\n",
    "# # Will make the chart with the recount of trials for each coherence and each sigma for each rat\n",
    "# for rat in range(len(rats)):\n",
    "#     rf.recount_trials(sigma_lists[rat],coherence_vectors[rat],length_lists[rat],rats[rat],coherences_lists[rat],directory_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sensitivity and bias using curve_fit\n",
    "all_sensitivity, all_bias = rf.compute_sensitivity(rats,coherences_lists,percentages_lists,sigma_lists,directory_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sensitivity and bias using curve_fit\n",
    "all_sensitivity_fit, all_bias_fit = rf.compute_sensitivity(rats,coherences_lists_fit,percentages_lists_fit,sigma_lists_fit,directory_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing bootstrap to compute confidence intervals\n",
    "n_trials = 10\n",
    "\n",
    "all_percentages_lists_boot = []\n",
    "all_coherences_lists_boot = [] \n",
    "all_length_lists_boot = [] \n",
    "all_length_all_rats_boot  = []\n",
    "for i in range(n_trials):\n",
    "    new_divided_sigma = rf.bootstrap(results_divided_sigma)\n",
    "    percentages_lists_boot, coherences_lists_boot, length_lists_boot, length_all_rats_boot = rf.compute_percentages(rats,new_divided_sigma,coherence_vectors)\n",
    "    all_percentages_lists_boot.append(percentages_lists_boot)\n",
    "    all_coherences_lists_boot.append(coherences_lists_boot)\n",
    "    all_length_lists_boot.append(length_lists_boot)\n",
    "    all_length_all_rats_boot.append(length_all_rats_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing bootstrap to compute confidence intervals\n",
    "n_trials = 10\n",
    "\n",
    "all_percentages_lists_boot_fit = []\n",
    "all_coherences_lists_boot_fit = [] \n",
    "all_length_lists_boot_fit = [] \n",
    "all_length_all_rats_boot_fit  = []\n",
    "for i in range(n_trials):\n",
    "    new_divided_sigma = rf.bootstrap(results_divided_sigma_fit)\n",
    "    percentages_lists_boot, coherences_lists_boot, length_lists_boot, length_all_rats_boot = rf.compute_percentages(rats,new_divided_sigma,coherence_vectors)\n",
    "    all_percentages_lists_boot_fit.append(percentages_lists_boot)\n",
    "    all_coherences_lists_boot_fit.append(coherences_lists_boot)\n",
    "    all_length_lists_boot_fit.append(length_lists_boot)\n",
    "    all_length_all_rats_boot_fit.append(length_all_rats_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute sensitivity and bias using curve_fit for the bootstrap data\n",
    "all_sensitivity_boot = []\n",
    "all_bias_boot = []\n",
    "for i in range(len(all_percentages_lists_boot)):\n",
    "    sensitivity_boot, bias_boot = rf.compute_sensitivity_boot(rats,all_coherences_lists_boot[i],all_percentages_lists_boot[i],sigma_lists)\n",
    "    all_sensitivity_boot.append(sensitivity_boot)\n",
    "    all_bias_boot.append(bias_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute sensitivity and bias using curve_fit for the bootstrap data\n",
    "all_sensitivity_boot_fit = []\n",
    "all_bias_boot_fit = []\n",
    "for i in range(len(all_percentages_lists_boot_fit)):\n",
    "    sensitivity_boot, bias_boot = rf.compute_sensitivity_boot(rats,all_coherences_lists_boot_fit[i],all_percentages_lists_boot_fit[i],sigma_lists)\n",
    "    all_sensitivity_boot_fit.append(sensitivity_boot)\n",
    "    all_bias_boot_fit.append(bias_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the confidence intervals for the sensitivity\n",
    "sensitivity_sigma = [np.zeros((len(sigma_lists[0]),n_trials)),np.zeros((len(sigma_lists[1]),n_trials)),np.zeros((len(sigma_lists[2]),n_trials)),np.zeros((len(sigma_lists[3]),n_trials)),\n",
    "                    np.zeros((len(sigma_lists[4]),n_trials)),np.zeros((len(sigma_lists[5]),n_trials)),np.zeros((len(sigma_lists[6]),n_trials))]\n",
    "\n",
    "for trial in range(len(all_sensitivity_boot)):\n",
    "    for rat in range(len(all_sensitivity_boot[trial])):\n",
    "        for sigm in range(len(all_sensitivity_boot[trial][rat])):\n",
    "             sensitivity_sigma[rat][sigm][trial] = all_sensitivity_boot[trial][rat][sigm]\n",
    "\n",
    "conf_intervals_sensitivity = []\n",
    "for rat in range(len(rats)):\n",
    "    sensitivity_rat = []\n",
    "    for a in range(len(all_sensitivity_boot[0][rat])):\n",
    "        sens = sensitivity_sigma[rat][a]\n",
    "\n",
    "        z = 1.96\n",
    "        conf_int = [np.mean(sens)-z*np.std(sens),np.mean(sens)+z*np.std(sens)]\n",
    "        sensitivity_rat.append(conf_int)\n",
    "\n",
    "    conf_intervals_sensitivity.append(sensitivity_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the confidence intervals for the sensitivity\n",
    "sensitivity_sigma_fit = [np.zeros((len(sigma_lists[0]),n_trials)),np.zeros((len(sigma_lists[1]),n_trials)),np.zeros((len(sigma_lists[2]),n_trials)),np.zeros((len(sigma_lists[3]),n_trials)),\n",
    "                    np.zeros((len(sigma_lists[4]),n_trials)),np.zeros((len(sigma_lists[5]),n_trials)),np.zeros((len(sigma_lists[6]),n_trials))]\n",
    "\n",
    "for trial in range(len(all_sensitivity_boot_fit)):\n",
    "    for rat in range(len(all_sensitivity_boot_fit[trial])):\n",
    "        for sigm in range(len(all_sensitivity_boot_fit[trial][rat])):\n",
    "             sensitivity_sigma_fit[rat][sigm][trial] = all_sensitivity_boot_fit[trial][rat][sigm]\n",
    "\n",
    "conf_intervals_sensitivity_fit = []\n",
    "for rat in range(len(rats)):\n",
    "    sensitivity_rat = []\n",
    "    for a in range(len(all_sensitivity_boot_fit[0][rat])):\n",
    "        sens = sensitivity_sigma_fit[rat][a]\n",
    "\n",
    "        z = 1.96\n",
    "        conf_int = [np.mean(sens)-z*np.std(sens),np.mean(sens)+z*np.std(sens)]\n",
    "        sensitivity_rat.append(conf_int)\n",
    "\n",
    "    conf_intervals_sensitivity_fit.append(sensitivity_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the bias confidence intervals\n",
    "bias_sigma = [np.zeros((len(sigma_lists[0]),n_trials)),np.zeros((len(sigma_lists[1]),n_trials)),np.zeros((len(sigma_lists[2]),n_trials)),np.zeros((len(sigma_lists[3]),n_trials)),\n",
    "                    np.zeros((len(sigma_lists[4]),n_trials)),np.zeros((len(sigma_lists[5]),n_trials)),np.zeros((len(sigma_lists[6]),n_trials))]\n",
    "\n",
    "for trial in range(len(all_bias_boot)):\n",
    "    for rat in range(len(all_bias_boot[trial])):\n",
    "        for sigm in range(len(all_bias_boot[trial][rat])):\n",
    "             bias_sigma[rat][sigm][trial] = all_bias_boot[trial][rat][sigm]\n",
    "\n",
    "conf_intervals_bias = []\n",
    "for rat in range(len(rats)):\n",
    "    bias_rat = []\n",
    "    for a in range(len(all_bias_boot[0][rat])):\n",
    "        bias = bias_sigma[rat][a]\n",
    "\n",
    "        z = 1.96\n",
    "        conf_int = [np.mean(bias)-z*np.std(bias),np.mean(bias)+z*np.std(bias)]\n",
    "        bias_rat.append(conf_int)\n",
    "\n",
    "    conf_intervals_bias.append(bias_rat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the bias confidence intervals\n",
    "bias_sigma_fit = [np.zeros((len(sigma_lists[0]),n_trials)),np.zeros((len(sigma_lists[1]),n_trials)),np.zeros((len(sigma_lists[2]),n_trials)),np.zeros((len(sigma_lists[3]),n_trials)),\n",
    "                    np.zeros((len(sigma_lists[4]),n_trials)),np.zeros((len(sigma_lists[5]),n_trials)),np.zeros((len(sigma_lists[6]),n_trials))]\n",
    "\n",
    "for trial in range(len(all_bias_boot_fit)):\n",
    "    for rat in range(len(all_bias_boot_fit[trial])):\n",
    "        for sigm in range(len(all_bias_boot_fit[trial][rat])):\n",
    "             bias_sigma_fit[rat][sigm][trial] = all_bias_boot_fit[trial][rat][sigm]\n",
    "\n",
    "conf_intervals_bias_fit = []\n",
    "for rat in range(len(rats)):\n",
    "    bias_rat = []\n",
    "    for a in range(len(all_bias_boot_fit[0][rat])):\n",
    "        bias = bias_sigma[rat][a]\n",
    "\n",
    "        z = 1.96\n",
    "        conf_int = [np.mean(bias)-z*np.std(bias),np.mean(bias)+z*np.std(bias)]\n",
    "        bias_rat.append(conf_int)\n",
    "\n",
    "    conf_intervals_bias_fit.append(bias_rat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot of the sensitivity over sigma\n",
    "for rat in range(len(rats)):\n",
    "    fig, axs = plt.subplots(figsize = (8,5))\n",
    "    conf_int = [[conf_intervals_sensitivity[rat][i][0] for i in range(len(sigma_lists[rat]))],[conf_intervals_sensitivity[rat][i][1] for i in range(len(sigma_lists[rat]))]]\n",
    "    conf_int_0 = []\n",
    "    conf_int_1 = []\n",
    "    new_sigma_list = []\n",
    "    new_sensitivity = []\n",
    "    for i in range(len(conf_int[0])):\n",
    "        if str(conf_int[0][i]) != \"nan\":\n",
    "            if all_sensitivity[rat][i] != None:\n",
    "\n",
    "                conf_int_0.append(conf_int[0][i]-all_sensitivity[rat][i])\n",
    "                conf_int_1.append(all_sensitivity[rat][i]-conf_int[1][i])\n",
    "                new_sigma_list.append(sigma_lists[rat][i])\n",
    "                new_sensitivity.append(all_sensitivity[rat][i])\n",
    "    conf_int = [conf_int_0,conf_int_1]\n",
    "    plt.errorbar(new_sigma_list,new_sensitivity,conf_int,marker='o',color= \"skyblue\")\n",
    "    conf_int = [[conf_intervals_sensitivity_fit[rat][i][0] for i in range(len(sigma_lists[rat]))],[conf_intervals_sensitivity_fit[rat][i][1] for i in range(len(sigma_lists[rat]))]]\n",
    "    conf_int_0 = []\n",
    "    conf_int_1 = []\n",
    "    new_sigma_list = []\n",
    "    new_sensitivity = []\n",
    "    for i in range(len(conf_int[0])):\n",
    "        if str(conf_int[0][i]) != \"nan\":\n",
    "            if all_sensitivity_fit[rat][i] != None:\n",
    "\n",
    "                conf_int_0.append(all_sensitivity_fit[rat][i]-conf_int[0][i])\n",
    "                conf_int_1.append(all_sensitivity_fit[rat][i]+conf_int[1][i])\n",
    "                new_sigma_list.append(sigma_lists[rat][i])\n",
    "                new_sensitivity.append(all_sensitivity_fit[rat][i])\n",
    "    conf_int = [conf_int_0,conf_int_1]\n",
    "    plt.fill_between(new_sigma_list,conf_int_0,conf_int_1,alpha=0.2,facecolor='#089FFF',\n",
    "    linewidth=4, linestyle='dashdot', antialiased=True)\n",
    "#     plt.axis([-0.1,0.9,-1,50])\n",
    "    \n",
    "    \n",
    "    hp.remove_axis(axs)\n",
    "    fig.suptitle(rats[rat]+\" sensitivity\",fontsize = 18)\n",
    "    fig.text(0.5, 0.02, \"Sigma\", ha='center',fontsize = 16)\n",
    "    fig.text(0.03, 0.5, \"Sensitivity\", va='center', rotation='vertical',fontsize = 18)\n",
    "#     fig.savefig(directory_images+'sensitivity/sensitivity_'+rats[rat]+'.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot of the bias over sigma\n",
    "for rat in range(len(rats)):\n",
    "    fig, axs = plt.subplots(figsize = (8,5))\n",
    "    conf_int = [[conf_intervals_bias[rat][i][0] for i in range(len(sigma_lists[rat]))],[conf_intervals_bias[rat][i][1] for i in range(len(sigma_lists[rat]))]]\n",
    "    conf_int_0 = []\n",
    "    conf_int_1 = []\n",
    "    new_sigma_list = []\n",
    "    new_bias = []\n",
    "    for i in range(len(conf_int[0])):\n",
    "        if str(conf_int[0][i]) != \"nan\":\n",
    "            if all_bias[rat][i] != None:\n",
    "                conf_int_0.append(conf_int[0][i]-all_bias[rat][i])\n",
    "                conf_int_1.append(all_bias[rat][i]-conf_int[1][i])\n",
    "                new_sigma_list.append(sigma_lists[rat][i])\n",
    "                new_bias.append(all_bias[rat][i])\n",
    "    conf_int = [conf_int_0,conf_int_1]\n",
    "    plt.errorbar(new_sigma_list,new_bias,conf_int,marker='o',color=\"skyblue\")\n",
    "    \n",
    "    \n",
    "    conf_int = [[conf_intervals_bias_fit[rat][i][0] for i in range(len(sigma_lists[rat]))],[conf_intervals_bias_fit[rat][i][1] for i in range(len(sigma_lists[rat]))]]\n",
    "    conf_int_0 = []\n",
    "    conf_int_1 = []\n",
    "    new_sigma_list = []\n",
    "    new_bias = []\n",
    "    for i in range(len(conf_int[0])):\n",
    "        if str(conf_int[0][i]) != \"nan\":\n",
    "            if all_bias_fit[rat][i] != None:\n",
    "                conf_int_0.append(all_bias_fit[rat][i]-conf_int[0][i])\n",
    "                conf_int_1.append(all_bias_fit[rat][i]+conf_int[1][i])\n",
    "                new_sigma_list.append(sigma_lists[rat][i])\n",
    "                new_bias.append(all_bias_fit[rat][i])\n",
    "    plt.fill_between(new_sigma_list,conf_int_0,conf_int_1,alpha=0.2,facecolor='#089FFF',\n",
    "    linewidth=4, linestyle='dashdot', antialiased=True)    \n",
    "    \n",
    "    \n",
    "    plt.plot(new_sigma_list,new_bias,marker = 's')\n",
    "    plt.hlines(0,-0.1,0.9,color = \"grey\",linestyles = \"--\")\n",
    "    plt.axis([-0.1,0.9,-0.8,0.3])\n",
    "    hp.remove_axis(axs)\n",
    "    fig.suptitle(rats[rat]+\" bias\",fontsize = 18)\n",
    "    fig.text(0.5, 0.02, \"Sigma\", ha='center',fontsize = 16)\n",
    "    fig.text(0.03, 0.5, \"Bias\", va='center', rotation='vertical',fontsize = 18)\n",
    "#     fig.savefig(directory_images+'bias/bias'+rats[rat]+'.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data by sigma (without taking coherence into account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_divided_sigma_nocoh_fit = [] # results_divided_sigma_nocoh[rat][sigma][reward,decision,performance,stim]\n",
    "perc_sigma_nocoh_fit = []\n",
    "# Dividing the data over sigma (not by coherence)\n",
    "results_divided_sigma_nocoh = [] # results_divided_sigma_nocoh[rat][sigma][reward,decision,performance,stim]\n",
    "perc_sigma_nocoh = []\n",
    "\n",
    "sigmas_lists =[[0.0,0.1129],[0.225,0.576],[0.8,0.8]] \n",
    "\n",
    "\n",
    "for rat in range(len(rats)):\n",
    "    divided_sigma = []\n",
    "    for sigma in sigmas_lists:\n",
    "        divided_sigma.append(rf.divide_sigma_1(rewards[rat],choices[rat],performances[rat],stimulus[rat],target_sigmas[rat],sigma))\n",
    "    perc = []\n",
    "    number_trials = []\n",
    "    results_divided_sigma_nocoh.append(divided_sigma)\n",
    "    for i in range(len(divided_sigma)):\n",
    "        perc.append(sum(results_divided_coherence[rat][i][2])/len(results_divided_coherence[rat][i][2]))\n",
    "        number_trials.append(len(results_divided_coherence[rat][i][1]))\n",
    "    perc_sigma_nocoh.append(perc)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(figsize = (8,5))\n",
    "    plt.plot([s[0] for s in sigmas_lists],perc,marker = 'o',color=\"skyblue\")\n",
    "    plt.axis([0,1,0,1])\n",
    "    hp.remove_axis(axs)\n",
    "    fig.suptitle(rats[rat]+\" accuracy\",fontsize = 18)\n",
    "    fig.text(0.5, 0.02, \"Sigma\", ha='center',fontsize = 16)\n",
    "    fig.text(0.03, 0.5, \"Accuracy\", va='center', rotation='vertical',fontsize = 18)\n",
    "#     fig.savefig(directory_images+'accuracy_vs_sigma/accuracy_vs_sigma'+rats[rat]+'.png', bbox_inches = 'tight')\n",
    "    divided_sigma = []\n",
    "        \n",
    "    for sigma in sigmas_lists:\n",
    "        divided_sigma.append(rf.divide_sigma_1(rewards[rat],choices_fit[rat],performances[rat],stimulus[rat],target_sigmas[rat],sigma))\n",
    "    perc = []\n",
    "    number_trials = []\n",
    "    results_divided_sigma_nocoh_fit.append(divided_sigma)\n",
    "    for i in range(len(divided_sigma)):\n",
    "        perc.append(sum(results_divided_coherence_fit[rat][i][2])/len(results_divided_coherence_fit[rat][i][2]))\n",
    "        number_trials.append(len(results_divided_coherence_fit[rat][i][1]))\n",
    "    perc_sigma_nocoh_fit.append(perc)\n",
    "\n",
    "\n",
    "    plt.plot([s[0] for s in sigmas_lists],perc,marker = 'o',color=\"red\")\n",
    "    plt.axis([0,1,0,1])\n",
    "    hp.remove_axis(axs)\n",
    "#     fig.suptitle(rats[rat]+\" accuracy\",fontsize = 18)\n",
    "#     fig.text(0.5, 0.02, \"Sigma\", ha='center',fontsize = 16)\n",
    "#     fig.text(0.03, 0.5, \"Accuracy\", va='center', rotation='vertical',fontsize = 18)\n",
    "#     fig.savefig(directory_images+'accuracy_vs_sigma/accuracy_vs_sigma'+rats[rat]+'.png', bbox_inches = 'tight')\n",
    "\n",
    "# PODRIA FER ELS CONFIDENCE INTERVALS AQU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rat in range(len(rats)):\n",
    "    for sig in range(len(results_divided_sigma_nocoh[rat])):\n",
    "        for sti in range(len(results_divided_sigma_nocoh[rat][sig][3])):\n",
    "            if len(results_divided_sigma_nocoh[rat][sig][3][sti]) == 20:\n",
    "                group = 2\n",
    "\n",
    "                results_divided_sigma_nocoh[rat][sig][3][sti] = np.ndarray.tolist(np.asarray(results_divided_sigma_nocoh[rat][sig][3][sti]).reshape(-1, group).mean(axis=1))\n",
    "                \n",
    "for rat in range(len(rats)):\n",
    "    for sig in range(len(results_divided_sigma_nocoh_fit[rat])):\n",
    "        for sti in range(len(results_divided_sigma_nocoh_fit[rat][sig][3])):\n",
    "            if len(results_divided_sigma_nocoh_fit[rat][sig][3][sti]) == 20:\n",
    "                group = 2\n",
    "\n",
    "                results_divided_sigma_nocoh_fit[rat][sig][3][sti] = np.ndarray.tolist(np.asarray(results_divided_sigma_nocoh_fit[rat][sig][3][sti]).reshape(-1, group).mean(axis=1))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divided_time_PK(rats,results_divided_sigma_nocoh,results_divided_sigma_nocoh_fit,sigma_lists,rats_list,directory_images):\n",
    "     # results_divided_sigma_coh[rat][sigma][reward,decision,performance,stim]\n",
    "        fig, ((axs1,axs2,axs3)) = plt.subplots(1,3,figsize = (18,4))\n",
    "\n",
    "        axs = [0,axs1,axs2,axs3,0,0]\n",
    "        color = [0,\"maroon\",\"brown\",\"red\",\"orangered\",\"orange\",\"yellow\"]\n",
    "        index = 1\n",
    "        aranges = [np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1)]\n",
    "        for rat in rats:\n",
    "            for a in aranges[rat]:\n",
    "                print(rat,len(results_divided_sigma_nocoh[rat][a][3][0]))\n",
    "                try:\n",
    "                    conf_int = PK(results_divided_sigma_nocoh[rat][a][1],results_divided_sigma_nocoh[rat][a][3],axs[index],color[index])            \n",
    "                    print(np.round((sigmas_lists[a][0]+sigmas_lists[a][1])/2,2))\n",
    "\n",
    "                    conf_int_fit = PK_fit(results_divided_sigma_nocoh_fit[rat][a][1],results_divided_sigma_nocoh_fit[rat][a][3],axs[index],color[index])            \n",
    "                    axs[index].set_title(\"Sigma = \"+str(np.round((sigmas_lists[a][0]+sigmas_lists[a][1])/2,2)))\n",
    "                    axs[index].spines['right'].set_visible(False)\n",
    "                    axs[index].spines['top'].set_visible(False)\n",
    "                    axs[index].set_ylabel(\"Weight\",fontsize = 24)\n",
    "                    axs[index].set_xlabel(\"Frame n\",fontsize = 24)\n",
    "                except:\n",
    "                    print(\"another error\")\n",
    "                index +=1\n",
    "#         plt.ylim(-1.5,1.5)    \n",
    "#         fig.suptitle(\"PK for \"+rats_list[rat],fontsize = 18)\n",
    "        fig.text(0.5, 0.001, 'Frame n', ha='center',fontsize = 16)\n",
    "        fig.text(0.08, 0.5, 'Impact', va='center', rotation='vertical',fontsize = 18)\n",
    "        \n",
    "#         fig.savefig(directory_images+'PK/temporal_PK'+rats_list[rat]+'.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divided_time_PK(rats,results_divided_sigma_nocoh,results_divided_sigma_nocoh_fit,sigma_lists,rats_list,directory_images):\n",
    "     # results_divided_sigma_coh[rat][sigma][reward,decision,performance,stim]\n",
    "        fig, axs3 = plt.subplots()\n",
    "\n",
    "        axs = [0,axs1,axs2,axs3,0,0]\n",
    "        color = [0,\"maroon\",\"brown\",\"red\",\"orangered\",\"orange\",\"yellow\"]\n",
    "        index = 1\n",
    "        aranges = [np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1),np.arange(0,3,1)]\n",
    "        for rat in rats:\n",
    "            for a in aranges[rat]:\n",
    "                print(rat,len(results_divided_sigma_nocoh[rat][a][3][0]))\n",
    "                try:\n",
    "                    conf_int = PK(results_divided_sigma_nocoh[rat][a][1],results_divided_sigma_nocoh[rat][a][3],axs[index],color[index])            \n",
    "                    print(np.round((sigmas_lists[a][0]+sigmas_lists[a][1])/2,2))\n",
    "\n",
    "                    conf_int_fit = PK_fit(results_divided_sigma_nocoh_fit[rat][a][1],results_divided_sigma_nocoh_fit[rat][a][3],axs[index],color[index])            \n",
    "#                     axs[index].set_title(\"Sigma = \"+str(np.round((sigmas_lists[a][0]+sigmas_lists[a][1])/2,2)))\n",
    "                    axs[index].spines['right'].set_visible(False)\n",
    "                    axs[index].spines['top'].set_visible(False)\n",
    "                    axs[index].set_ylabel(\"Weight\",fontsize = 24)\n",
    "                    axs[index].set_xlabel(\"Frame n\",fontsize = 24)\n",
    "                    plt.xticks(fontsize = 22)\n",
    "                    plt.yticks([0,0.5,1],fontsize = 22)\n",
    "                except:\n",
    "                    print(\"another error\")\n",
    "                index +=1\n",
    "#         plt.ylim(-1.5,1.5)    \n",
    "#         fig.suptitle(\"PK for \"+rats_list[rat],fontsize = 18)\n",
    "#         fig.text(0.5, 0.001, 'Frame n', ha='center',fontsize = 16)\n",
    "#         fig.text(0.08, 0.5, 'Impact', va='center', rotation='vertical',fontsize = 18)\n",
    "        \n",
    "#         fig.savefig(directory_images+'PK/temporal_PK'+rats_list[rat]+'.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PK(decision,stim,axs,col):\n",
    "#     logit_mod = sm.Logit(decision, stim)\n",
    "#     result = logit_mod.fit()\n",
    "\n",
    "#     pars_list =result.params\n",
    "#     confidence_interval = result.conf_int()\n",
    "#     conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "#     conf_int = [pars_list-conf_int[0],conf_int[1]-pars_list]\n",
    "#     axs.errorbar(np.arange(0,len(pars_list),1),pars_list,conf_int,color = col,marker='s')\n",
    "\n",
    "#     return(confidence_interval)\n",
    "\n",
    "def PK(decision,stim,axs,col):\n",
    "\n",
    "    logit_mod = sm.Logit(decision, stim)\n",
    "    result = logit_mod.fit()\n",
    "\n",
    "    pars_list =result.params\n",
    "    confidence_interval = result.conf_int()\n",
    "    conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "    conf_int = [pars_list-conf_int[0],conf_int[1]-pars_list]\n",
    "    axs.errorbar(np.arange(0,len(pars_list),1),pars_list,conf_int,color = \"cornflowerblue\",marker='s',linewidth = 4)\n",
    "#     axs.set_ylim(top=max(pars_list)+0.4,bottom =min(pars_list)-0.4)    \n",
    "\n",
    "#     return(confidence_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PK_fit(decision,stim,axs,col):\n",
    "    logit_mod = sm.Logit(decision, stim)\n",
    "    result = logit_mod.fit()\n",
    "\n",
    "    pars_list =result.params\n",
    "    confidence_interval = result.conf_int()\n",
    "    conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "#     conf_int = [pars_list-conf_int[0],conf_int[1]-pars_list]\n",
    "#     axs.errorbar(np.arange(0,len(pars_list),1),pars_list,conf_int,marker='s')\n",
    "\n",
    "    axs.fill_between(np.arange(0,len(pars_list),1),conf_int[0],conf_int[1],alpha=0.4, facecolor='grey',\n",
    "    linewidth=4, linestyle='dashdot', antialiased=True)\n",
    "#     axs.set_ylim(top=max(pars_list)+0.4,bottom =min(pars_list)-0.4)    \n",
    "\n",
    "    return(confidence_interval)\n",
    "\n",
    "\n",
    "# def PK_fit(decision,stim,axs,col):\n",
    "#     # provar sklearn\n",
    "#     pars_list = LogisticRegression().get_params(stim, decision)\n",
    "# #     result = logit_mod.fit()\n",
    "\n",
    "# #     pars_list =result.params\n",
    "    \n",
    "#     confidence_interval = result.conf_int()\n",
    "#     confidence_interval = decision_function(X)\n",
    "#     conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "#     conf_int = [pars_list-conf_int[0],conf_int[1]-pars_list]\n",
    "#     axs.fill_between(np.arange(0,len(pars_list),1),conf_int[0],conf_int[1],alpha=0.2, facecolor='#089FFF',\n",
    "#     linewidth=4, linestyle='dashdot', antialiased=True)\n",
    "\n",
    "#     return(confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_divided_sigma_nocoh[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rats_sec = [1,2,4]\n",
    "plt.figure()\n",
    "divided_time_PK([4],results_divided_sigma_nocoh,results_divided_sigma_nocoh_fit,sigma_lists,rats,directory_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Kernel for all sigmas for each rat\n",
    "\n",
    "# For each stimulus, how many stimulus are from -1 to -0.9, etc to get a transformed stimulus, then make a logistic regression\n",
    "color = [0,\"maroon\",\"brown\",\"red\",\"orangered\",\"orange\",\"yellow\"]\n",
    "\n",
    "new_transf_stim = rf.transformed_stimulus(stimulus)\n",
    "# new_transf_sec_stim  = rf.transformed_stimulus([stimulus[0],stimulus[3]])\n",
    "new_dec_half = choices\n",
    "# new_dec_sec = [choices[0],choices[3]]\n",
    "new_dec_half_fit = choices_fit\n",
    "# new_dec_sec_fit = [choices_fit[0],choices_fit[3]]\n",
    "\n",
    " \n",
    "for rat in [0,1,2,3,4,5,6]:\n",
    "#     try:\n",
    "    rats_half = [0,1,2,3,4,5,6]\n",
    "\n",
    "    fig, axs = plt.subplots(figsize = (8,5))\n",
    "    plt.xticks([0,2.5,5,7.5,10],[\"-1\",\"-0.5\",\"0\",\"0.5\",\"1\"])\n",
    "    print(len(new_dec_half[rat]),len(new_transf_stim[rat]))\n",
    "    logit_mod = sm.Logit(new_dec_half[rat], new_transf_stim[rat])\n",
    "    result = logit_mod.fit()\n",
    "    pars_list =result.params\n",
    "    confidence_interval = result.conf_int()\n",
    "    conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "    conf_int = [pars_list-conf_int[0],conf_int[1]-pars_list]\n",
    "    x_values = np.arange(0,len(pars_list),1)\n",
    "    plt.errorbar(x_values,pars_list,conf_int,color = \"cornflowerblue\",linewidth = 4,marker='o')\n",
    "    \n",
    "    slope, intercept = np.polyfit([x_values[4],x_values[5],x_values[6]], [pars_list[4],pars_list[5],pars_list[6]], 1)\n",
    "    abline_values = [slope * i + intercept for i in x_values]\n",
    "    plt.plot(x_values, abline_values,'grey', linestyle = \"dashed\")\n",
    "    \n",
    "    logit_mod = sm.Logit(new_dec_half_fit[rat], new_transf_stim[rat])\n",
    "    result = logit_mod.fit()\n",
    "    pars_list =result.params\n",
    "    confidence_interval = result.conf_int()\n",
    "    conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "    x_values = np.arange(0,len(pars_list),1)\n",
    "    plt.fill_between(x_values,conf_int[0],conf_int[1],alpha=0.4,facecolor='grey', linewidth=4, linestyle='dashdot', antialiased=True,label = \"Fitted model\")\n",
    "    \n",
    "\n",
    "#     fig.suptitle(\"Spatial Kernel \"+rats[rat],fontsize = 18)\n",
    "    fig.text(0.5, -0.07, \"Coherence value\", ha='center',fontsize = 30)\n",
    "    fig.text(-0.07, 0.5, \"Spatial Kernel\", va='center', rotation='vertical',fontsize = 30)\n",
    "\n",
    "    plt.xticks(fontsize = 28)\n",
    "    plt.yticks(fontsize = 28)\n",
    "    plt.ylim(-0.5,0.5)\n",
    "    hp.remove_axis(axs)\n",
    "#     fig.savefig(directory_images+'PK/spatial_PK_'+rats[rats_half[rat]]+'_half_sec.png', bbox_inches = 'tight')\n",
    "#     except:\n",
    "#         print(\"no ha funcionat\"+str(rat))\n",
    "\n",
    "# rats_sec = [0,3]\n",
    "        \n",
    "# for rat in range(len(rats_sec)):\n",
    "# #     try:\n",
    "# #         print(rat)\n",
    "#     fig, axs = plt.subplots(figsize = (8,5))\n",
    "\n",
    "#     plt.xticks([0,2.5,5,7.5,10], [\"-1\",\"-0.5\",\"0\",\"0.5\",\"1\"])\n",
    "#     logit_mod = sm.Logit(new_dec_sec[rat], new_transf_sec_stim[rat])\n",
    "#     result = logit_mod.fit()\n",
    "#     pars_list =result.params\n",
    "#     confidence_interval = result.conf_int()\n",
    "#     conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "#     conf_int = [pars_list-conf_int[0],conf_int[1]-pars_list]\n",
    "#     plt.errorbar(np.arange(0,len(pars_list),1),pars_list,conf_int,marker='o')\n",
    "#     plt.ylim(-0.5,0.5)\n",
    "\n",
    "#     x_values = np.arange(0,len(pars_list),1)\n",
    "\n",
    "#     slope, intercept = np.polyfit([x_values[4],x_values[5],x_values[6]], [pars_list[4],pars_list[5],pars_list[6]], 1)\n",
    "#     abline_values = [slope * i + intercept for i in x_values]\n",
    "#     plt.plot(x_values, abline_values,'grey', linestyle = \"dashed\")\n",
    "#     plt.ylim(-0.5,0.5)\n",
    "    \n",
    "#     logit_mod = sm.Logit(new_dec_sec_fit[rat], new_transf_sec_stim[rat])\n",
    "#     result = logit_mod.fit()\n",
    "#     pars_list =result.params\n",
    "#     confidence_interval = result.conf_int()\n",
    "#     conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "#     x_values = np.arange(0,len(pars_list),1)\n",
    "#     plt.fill_between(x_values,conf_int[0],conf_int[1],alpha=0.2,facecolor='#089FFF', linewidth=4, linestyle='dashdot', antialiased=True,label = \"Fitted model\")\n",
    "    \n",
    "#     fig.suptitle(\"Spatial Kernel \"+rats[rats_sec[rat]],fontsize = 18)\n",
    "#     fig.text(0.5, 0.02, \"Coherence value\", ha='center',fontsize = 16)\n",
    "#     fig.text(0.03, 0.5, \"Spatial Kernel\", va='center', rotation='vertical',fontsize = 18)\n",
    "\n",
    "#     hp.remove_axis(axs)\n",
    "#     fig.savefig(directory_images+'PK/spatial_PK_'+rats[rats_sec[rat]]+'_sec.png', bbox_inches = 'tight')\n",
    "# #     except:\n",
    "# #         print(\"no ha funcionat\"+str(rat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Kernel for all sigmas for each rat\n",
    "\n",
    "# For each stimulus, how many stimulus are from -1 to -0.9, etc to get a transformed stimulus, then make a logistic regression\n",
    "color = [0,\"maroon\",\"brown\",\"red\",\"orangered\",\"orange\",\"yellow\"]\n",
    "\n",
    "new_transf_stim = rf.transformed_stimulus(stimulus)\n",
    "# new_transf_sec_stim  = rf.transformed_stimulus([stimulus[0],stimulus[3]])\n",
    "new_dec_half = choices\n",
    "# new_dec_sec = [choices[0],choices[3]]\n",
    "new_dec_half_fit = choices_fit\n",
    "# new_dec_sec_fit = [choices_fit[0],choices_fit[3]]\n",
    "\n",
    " \n",
    "for rat in [0,1,2,3,4,5,6]:\n",
    "#     try:\n",
    "    rats_half = [0,1,2,3,4,5,6]\n",
    "\n",
    "    fig, axs = plt.subplots(figsize = (8,5))\n",
    "    plt.xticks([0,2.5,5,7.5,10],[\"-1\",\"-0.5\",\"0\",\"0.5\",\"1\"])\n",
    "    print(len(new_dec_half[rat]),len(new_transf_stim[rat]))\n",
    "    logit_mod = sm.Logit(new_dec_half[rat], new_transf_stim[rat])\n",
    "    result = logit_mod.fit()\n",
    "    pars_list =result.params\n",
    "    confidence_interval = result.conf_int()\n",
    "    conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "    conf_int = [pars_list-conf_int[0],conf_int[1]-pars_list]\n",
    "    x_values = np.arange(0,len(pars_list),1)\n",
    "    plt.errorbar(x_values,pars_list,conf_int,marker='o',color=\"cornflowerblue\",linewidth=4)\n",
    "    \n",
    "    slope, intercept = np.polyfit([x_values[4],x_values[5],x_values[6]], [pars_list[4],pars_list[5],pars_list[6]], 1)\n",
    "    abline_values = [slope * i + intercept for i in x_values]\n",
    "    plt.plot(x_values, abline_values,'grey', linestyle = \"dashed\")\n",
    "    \n",
    "    logit_mod = sm.Logit(new_dec_half_fit[rat], new_transf_stim[rat])\n",
    "    result = logit_mod.fit()\n",
    "    pars_list =result.params\n",
    "    confidence_interval = result.conf_int()\n",
    "    conf_int = [[i[0] for i in confidence_interval],[i[1] for i in confidence_interval]]\n",
    "    x_values = np.arange(0,len(pars_list),1)\n",
    "#     plt.fill_between(x_values,conf_int[0],conf_int[1],alpha=0.2,facecolor='#089FFF', linewidth=4, linestyle='dashdot', antialiased=True,label = \"Fitted model\")\n",
    "    \n",
    "\n",
    "    fig.suptitle(\"Spatial Kernel \"+rats[rat],fontsize = 20)\n",
    "    fig.text(0.5, 0.02, \"Coherence value\", ha='center',fontsize = 20)\n",
    "    fig.text(0.03, 0.5, \"Spatial Kernel\", va='center', rotation='vertical',fontsize = 20)\n",
    "    plt.xticks(fontsize=18)\n",
    "\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    plt.ylim(-0.5,0.5)\n",
    "    hp.remove_axis(axs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
